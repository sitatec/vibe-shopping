from typing import Generator

import numpy as np
import torch
import spaces
from kokoro import KPipeline, KModel

__all__ = ["text_to_speech"]

VOICES = {
    # American English
    "ENðŸ‡ºðŸ‡¸ Heart ðŸ‘©": "af_heart",
    "ENðŸ‡ºðŸ‡¸ Bella ðŸ‘©": "af_bella",
    "ENðŸ‡ºðŸ‡¸ Michael ðŸ‘¨": "am_michael",
    "ENðŸ‡ºðŸ‡¸ Fenrir ðŸ‘¨": "am_fenrir",
    # British English
    "ENðŸ‡¬ðŸ‡§ Emma ðŸ‘©": "bf_emma",
    "ENðŸ‡¬ðŸ‡§ George ðŸ‘¨": "bm_george",
    # Japanese
    "JAðŸ‡¯ðŸ‡µ Alpha ðŸ‘©": "jf_alpha",
    "JAðŸ‡¯ðŸ‡µ Kumo ðŸ‘¨": "jm_kumo",
    # Mandarin Chinese
    "ZHðŸ‡¨ðŸ‡³ Xiaoni ðŸ‘©": "zf_xiaoni",
    "ZHðŸ‡¨ðŸ‡³ Yunjian ðŸ‘¨": "zm_yunjian",
    # Spanish
    "ESðŸ‡ªðŸ‡¸ Dora ðŸ‘©": "ef_dora",
    "ESðŸ‡ªðŸ‡¸ Alex ðŸ‘¨": "em_alex",
    # French
    "FRðŸ‡«ðŸ‡· Siwis ðŸ‘©": "ff_siwis",
    # Hindi
    "HIðŸ‡®ðŸ‡³ Beta ðŸ‘©": "hf_beta",
    "HIðŸ‡®ðŸ‡³ Omega ðŸ‘¨": "hm_omega",
    # Italian
    "ITðŸ‡®ðŸ‡¹ Sara ðŸ‘©": "if_sara",
    "ITðŸ‡®ðŸ‡¹ Nicola ðŸ‘¨": "im_nicola",
    # Brazilian Portuguese
    "PTðŸ‡§ðŸ‡· Dora ðŸ‘©": "pf_dora",
    "PTðŸ‡§ðŸ‡· Santa ðŸ‘¨": "pm_santa",
}

device = 0 if torch.cuda.is_available() else "cpu"
model = KModel().to(device).eval()

# Create a pipeline for each language. Kokoro language codes:
# ðŸ‡ºðŸ‡¸ 'a' => American English, ðŸ‡¬ðŸ‡§ 'b' => British English
# ðŸ‡ªðŸ‡¸ 'e' => Spanish es
# ðŸ‡«ðŸ‡· 'f' => French fr-fr
# ðŸ‡®ðŸ‡³ 'h' => Hindi hi
# ðŸ‡®ðŸ‡¹ 'i' => Italian it
# ðŸ‡¯ðŸ‡µ 'j' => Japanese: pip install misaki[ja]
# ðŸ‡§ðŸ‡· 'p' => Brazilian Portuguese pt-br
# ðŸ‡¨ðŸ‡³ 'z' => Mandarin Chinese: pip install misaki[zh]
pipes = {
    lang_code: KPipeline(lang_code=lang_code, model=model, device=device)
    for lang_code in "abjzefhip"
}

# Preload voices into pipelines
for voice_code in VOICES.values():
    # First letter of the voice code is the language code (kokoro format)
    lang_code = voice_code[0]
    if lang_code in pipes:
        pipes[lang_code].load_voice(voice_code)

@spaces.GPU(duration=10)
def text_to_speech(text: str, voice: str = "af_heart") -> Generator[np.ndarray, None, None]:
    """
    Convert text to speech using the specified voice.
    
    Args:
        text (str): The text to convert to speech.
        voice (str): The voice to use for the conversion. Default to af_heart
    
    Returns:
        np.ndarray: The audio as a NumPy array.
    """
    if voice not in VOICES:
        raise ValueError(f"Voice '{voice}' is not available.")
    
    pipe = pipes[voice[0]]

    for _, __, result in pipe(text, voice=voice):
        yield result.audio.numpy()
